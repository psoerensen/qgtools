[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "qgtools",
    "section": "",
    "text": "qgtools is a framework for specifying and fitting mixed and hierarchical models, with a focus on quantitative genetics, high-dimensional predictors, and complex covariance structures.\nThe key idea behind qgtools is to separate model specification from model fitting, allowing the same model to be estimated using different software backends and estimation paradigms within a unified modeling framework."
  },
  {
    "objectID": "index.html#overview",
    "href": "index.html#overview",
    "title": "qgtools",
    "section": "",
    "text": "qgtools is a framework for specifying and fitting mixed and hierarchical models, with a focus on quantitative genetics, high-dimensional predictors, and complex covariance structures.\nThe key idea behind qgtools is to separate model specification from model fitting, allowing the same model to be estimated using different software backends and estimation paradigms within a unified modeling framework."
  },
  {
    "objectID": "index.html#core-ideas-and-orthogonal-layers",
    "href": "index.html#core-ideas-and-orthogonal-layers",
    "title": "qgtools",
    "section": "Core ideas and orthogonal layers",
    "text": "Core ideas and orthogonal layers\nqgtools separates model specification into independent, orthogonal layers.\nEach layer answers a distinct modeling question and can be modified without affecting the others.\n\nFormulas — what enters the model\nPer-trait formulas define responses, fixed effects, and named random or latent effects (e.g. (1 | id)).\nFormulas describe which effects exist, but not how their covariance is modeled.\nKernels and features — how effects act on the data\nqgtools supports two complementary mechanisms:\n\nKernels define implicit covariance structures across individuals or traits\n(e.g. pedigree, GRM, spatial or temporal correlation).\nFeature matrices define explicit linear predictors with potentially very large numbers of coefficients (e.g. genotypes, transcriptomics, other omics layers).\n\nBoth kernels and features are reusable, standalone objects that can be shared across models and estimation tasks.\nVariance components or priors — how much variation is attributed\nEach effect is paired with either:\n\nvariance components (vc()) for REML or solver-based estimation, or\n\nprior distributions (prior()) for Bayesian inference.\n\nFor feature-based effects, optional featureSets allow effects to be decomposed into multiple components with separate variance parameters.\nTask — how the model is fitted\nEstimation is controlled by gfit() via task = \"reml\", \"solve\", or \"bayes\", without changing the model structure.\nData — where the information comes from\nData are treated as abstract data sources, enabling transparent use of in-memory or disk-backed datasets (e.g. PLINK files, HDF5 matrices).\n\nAll layers are specified independently and validated jointly at fit time."
  },
  {
    "objectID": "index.html#kernel-and-feature-objects-are-lightweight-descriptors",
    "href": "index.html#kernel-and-feature-objects-are-lightweight-descriptors",
    "title": "qgtools",
    "section": "Kernel and feature objects are lightweight descriptors",
    "text": "Kernel and feature objects are lightweight descriptors\nKernel and feature objects in qgtools are designed as lightweight descriptors rather than containers of explicit model matrices or parameters. In particular, they do not store large covariance matrices or design matrices in memory by default.\nInstead, these objects describe how model components should be constructed or accessed by downstream computational backends:\n\nKernel objects specify how covariance should be induced across levels of an effect\n(e.g. from pedigree information, precomputed relationship matrices, or other structured sources).\nFeature objects specify how high-dimensional predictors enter the model\n(e.g. genotype matrices, transcriptomic measurements, or other omics features),\npotentially stored on disk and accessed in a streaming or block-wise fashion.\n\nDepending on the estimation task and backend, covariance and linear predictors may be:\n\nderived implicitly from pedigree or relationship information,\ncomputed on the fly from feature matrices without forming explicit covariance matrices, or\naccessed from precomputed objects supplied by the user.\n\nThis abstraction decouples statistical model specification from data representation and numerical implementation. As a result, the same model formulation and user-facing code can be applied seamlessly across a wide range of data scales—from small illustrative examples to very large genomic or multi-omics datasets—without modification.\nBy deferring matrix construction and data access to backend-specific implementations, qgtools achieves both flexibility and scalability while preserving a clear and consistent statistical interface.\n\nVariance components vs priors\nClassical mixed models associate kernels or features with variance components (vc()),\nwhile Bayesian models replace these with explicit prior distributions (prior()),\nwithout changing formulas, kernels, or feature definitions."
  },
  {
    "objectID": "index.html#simple-example-to-illustrate-the-concept",
    "href": "index.html#simple-example-to-illustrate-the-concept",
    "title": "qgtools",
    "section": "Simple example to illustrate the concept",
    "text": "Simple example to illustrate the concept\nThe following example shows a minimal linear mixed model and illustrates how qgtools separates data input, model structure, covariance specification, and estimation.\n\n## ---------------------------------------------------------------\n## Data input\n## ---------------------------------------------------------------\n## Observational data provide phenotypes and covariates referenced\n## in the model formulas.\n\ndata &lt;- makeDataSource(\n  source = \"data.txt\",\n  format = \"CSV\"\n)\n\n## ---------------------------------------------------------------\n## Model structure (formulas)\n## ---------------------------------------------------------------\n## Formulas define which effects enter the model,\n## but not how covariance is modeled.\n\nformulas &lt;- list(\n  BW = BW ~ sex + (1 | id)\n)\n\n## ---------------------------------------------------------------\n## Covariance specification (kernels + variance components)\n## ---------------------------------------------------------------\n## The pedigree kernel defines how covariance is induced\n## across levels of the 'id' effect.\n\nPED &lt;- makePEDlist(fnPED = \"pedigree.txt\", \n                   method=\"S-D-NonInbred\")\n\nvcs &lt;- list(\n  animal = vc(\n    variable = \"id\",\n    traits   = \"BW\",\n    kernel   = PED,\n    start   = 1.0\n  ),\n  residual = vc(\n    variable = \"residual\",\n    traits   = \"BW\",\n    start   = 1.0\n  )\n)\n\n## ---------------------------------------------------------------\n## Model fitting\n## ---------------------------------------------------------------\n## The estimation task determines how the model is fit,\n## without changing the model structure.\n\nfit &lt;- gfit(\n  formulas = formulas,\n  data     = data,\n  vc       = vcs,\n  task     = \"reml\"\n)\n\nThe same model structure can be estimated as a Bayesian model by replacing vc() with prior() and setting task=“bayes”, without changing the formulas, kernels or data."
  },
  {
    "objectID": "index.html#model-validation-and-interoperability",
    "href": "index.html#model-validation-and-interoperability",
    "title": "qgtools",
    "section": "Model validation and interoperability",
    "text": "Model validation and interoperability\nBefore fitting, qgtools validates the full model bundle (data, formulas, kernels or features, and variance components or priors) to ensure internal consistency.\nThis validation step checks, for example, that: - all variables referenced in formulas are defined, - kernels or feature matrices are compatible with the corresponding effects, - trait dimensions are consistent across components, and - required variance components or priors are supplied.\nModel specifications can also be exported as structured JSON, allowing the same model to be executed by external backends, workflow engines, or non-R/Python environments.\n\nResidual effects\nThe residual variance is represented by a component with variable = \"residual\".\n\nThe residual effect is implicit in model formulas and must not appear as (1 | residual)\nIt must be explicitly specified using vc() (REML / solver) or prior() (Bayesian)\nResidual components never require a kernel or features"
  },
  {
    "objectID": "index.html#performance-and-deployment",
    "href": "index.html#performance-and-deployment",
    "title": "qgtools",
    "section": "Performance and deployment",
    "text": "Performance and deployment\nqgtools is designed as a lightweight R (or Python) interface to high-performance computational backends. Computationally intensive components—such as likelihood evaluation, large-scale linear algebra, and sampling—are implemented in compiled languages such as C++ or Fortran, while R (or Python) is used for model specification and orchestration.\nThis separation provides: - high computational performance, - scalability to large datasets, and - a clear boundary between model definition and numerical implementation.\nBy representing kernels and feature matrices as lightweight descriptors, qgtools avoids unnecessary memory usage and allows backends to construct covariance structures and linear predictors only when needed, using in-memory or disk-backed data as appropriate.\nFor deployment, qgtools can be packaged into containerized environments (e.g. Docker or Singularity), allowing models to be executed reproducibly on high-performance computing platforms and cloud infrastructures such as AWS and Azure. Containers bundle the required libraries and runtimes and can be deployed on HPC batch systems or cloud services without exposing source code.\nThis design enables qgtools to act as a unifying modeling layer while supporting multiple computational backends and deployment scenarios, from local workstations to large-scale cloud and HPC environments.\nqgtools handles large-scale data by taking advantage of:\n\nmulti-core processing using openMP\nmultithreaded matrix operations implemented in BLAS libraries (e.g. OpenBLAS, ATLAS, or MKL)\nfast and memory-efficient batch processing of feature data stored on disk (e.g. genotype data in PLINK bedfiles)"
  },
  {
    "objectID": "index.html#r-and-python-interfaces",
    "href": "index.html#r-and-python-interfaces",
    "title": "qgtools",
    "section": "R and Python interfaces",
    "text": "R and Python interfaces\nqgtools is designed with a language-agnostic core, allowing both R and Python interfaces to interact with the same underlying computational backends.\nModel specification and orchestration can be performed in either R or Python, while computationally intensive tasks (e.g. likelihood evaluation, large-scale linear algebra, sampling) are handled by shared C++/Fortran libraries.\nThis design ensures consistent results across interfaces and enables flexible deployment in cloud and HPC environments.\nThe example below shows the same mixed model specified in R and Python.\n\n## ---------------------------------------------------------------\n## R interface\n## ---------------------------------------------------------------\n## Model structure and covariance specification are expressed\n## using the same abstractions as in previous examples.\n\nformulas &lt;- list(\n  BW = BW ~ sex + reps + (1 | id)\n)\n\nvcs &lt;- list(\n  animal = vc(\n    variable = \"id\",\n    traits   = \"BW\",\n    kernel   = PED,\n    start   = 1.0\n  ),\n  residual = vc(\n    variable = \"residual\",\n    traits   = \"BW\",\n    start   = 1.0\n  )\n)\n\nfit &lt;- gfit(formulas, data, vcs, task = \"reml\")\n\n# ---------------------------------------------------------------\n# Python interface\n# ---------------------------------------------------------------\n# The same model specification expressed using Python syntax.\n# The underlying model and backend execution are identical.\n\nmodel = Model(\n    formulas={\n        \"BW\": \"BW ~ sex + reps + (1 | id)\"\n    },\n    vcs=[\n        vc(variable=\"id\", traits=[\"BW\"], kernel=PED, start=[1.0]),\n        vc(variable=\"residual\", traits=[\"BW\"], start=[1.0])\n    ]\n)\n\nfit = gfit(model, data, task=\"reml\")\n\nBoth interfaces construct the same internal model representation and invoke the same computational backend. Differences between R and Python are limited to syntax and user-facing language conventions."
  },
  {
    "objectID": "index.html#data-input-and-preparation",
    "href": "index.html#data-input-and-preparation",
    "title": "qgtools",
    "section": "Data input and preparation",
    "text": "Data input and preparation\nqgtools distinguishes between three broad classes of input data: standard observational data, structural data used to define covariance, and high-dimensional feature data. These inputs are prepared independently and combined later during model specification.\n\nStandard data: responses and covariates\nStandard data include phenotypes, covariates, and other observed variables referenced directly in model formulas.\nData may be provided either as an in-memory object or as a disk-backed source.\n\n## Observational data (phenotypes and covariates)\ndata &lt;- makeDataSource(\n  source = \"data.txt\",\n  format = \"CSV\"\n)\n\n\n\nStructural data: kernels\nKernels describe how covariance is induced across levels of a model component. They are typically used for low-dimensional random effects, such as pedigree- based genetic effects.\n\n## Pedigree-based kernel for additive genetic effects\nPED &lt;- makePEDlist(\n  fnPED  = \"pedigree.txt\",\n  method = \"S-D-NonInbred\"\n)\n\nKernel objects are lightweight descriptors and do not store explicit covariance matrices unless required by a backend.\nPrecomputed relationship matrices may also be supplied when appropriate, but are not required for most workflows.\n\n## Optional: precomputed genomic relationship matrix\nGRM &lt;- makeGRMlist(\n  fnGRM    = \"grm_inverse.txt\",\n  format   = \"BINARY\",\n  grm_type = \"G-inverse\"\n)\n\n\n\nHigh-dimensional predictors: feature matrices\nFeature matrices define explicit linear predictors with potentially very large numbers of coefficients. Typical examples include genotype matrices, transcriptomic measurements, or other omics data.\nFeature data are often stored on disk and accessed lazily by the backend. Here we illustrate this using PLINK based genotype files:\n\n## Genotype feature matrix (e.g. PLINK BED/BIM/FAM)\nfeatureMatrix &lt;- makeGlist(\n  bedfiles = c(\"chr1.bed\",\"chr2.bed\"),\n  bimfiles = c(\"chr1.bim\",\"chr2.bim\"),\n  famfiles = c(\"chr1.fam\",\"chr2.fam\")\n)\n\nOptional feature groupings can be supplied to define multiple variance components or prior structures over subsets of features.\n\n## Optional grouping of features\nfeatureSets &lt;- list(\n  set1 = 1:1000,\n  set2 = 1001:2000\n)\n\nFeature matrices and feature sets are later linked to model components via vc() (REML / solver) or prior() (Bayesian inference).\n\nBayesian multi-component linear models with marker-level priors\nMarker-level effects differ fundamentally from classical random effects:\n\nThey typically involve thousands to millions of coefficients\nCovariance is induced implicitly through the feature matrix (e.g. genotypes), linkage disequilibrium, and the chosen prior\nExplicit covariance matrices (e.g. GRMs) are usually avoided for scalability\n\nIn qgtools, marker effects are treated as feature-based model components. They are declared in the model formula as a named effect (e.g. (1 | id)), and linked to genotype data via a featureMatrix().\nRegularization and covariance structure are then specified through marker-level priors, such as bayesC(), optionally using featureSets to define multiple variance components over disjoint (or annotated) subsets of markers.\nThis approach mirrors how marker effects are handled in software such as BGLR and BayesR, while preserving a clear separation between:\n\nmodel structure (formulas and named effects),\ndata representation (feature matrices and feature sets), and\ninference (Bayesian priors or REML/solver-based estimation).\n\nUnlike classical low-dimensional random effects, marker effects are not associated with explicit covariance matrices at the observation level. Instead, their covariance is induced implicitly through the feature matrix and the prior, enabling scalable multi-component and multi-trait models."
  },
  {
    "objectID": "index.html#annotated-example-multivariate-mixed-bayesian-genomic-model",
    "href": "index.html#annotated-example-multivariate-mixed-bayesian-genomic-model",
    "title": "qgtools",
    "section": "Annotated example: Multivariate mixed / Bayesian genomic model",
    "text": "Annotated example: Multivariate mixed / Bayesian genomic model\n\n## ------------------------------------------------------------------\n## Per-trait model formulas\n## ------------------------------------------------------------------\n## Formulas declare *which* effects enter the model.\n## 'animal' represents the additive genetic effect (pedigree-based),\n## 'dam' captures a maternal environmental component, and\n## 'marker' represents high-dimensional marker effects\n## modeled through a feature matrix.\n\nformulas &lt;- list(\n  BW = BW ~ sex + reps + (1 | dam) + (1 | animal),\n  Gl = Gl ~ sex + reps + (1 | dam) + (1 | animal)\n)\n\n## ------------------------------------------------------------------\n## Kernel-based effect: pedigree (random effect)\n## ------------------------------------------------------------------\n## Pedigree effects are naturally expressed via kernels.\n\n## Pedigree-based kernel for additive genetic effects\nPED &lt;- makePEDlist(\n  fnPED  = \"pedigree.txt\",\n  method = \"S-D-NonInbred\"\n)\n\n\n## ------------------------------------------------------------------\n## Feature-based effect: markers (high-dimensional predictors)\n## ------------------------------------------------------------------\n## Marker effects are defined through a feature matrix\n\n## Genotype feature matrix (e.g. PLINK BED/BIM/FAM)\nfeatureMatrix &lt;- makeGlist(\n  bedfiles = c(\"chr1.bed\",\"chr2.bed\"),\n  bimfiles = c(\"chr1.bim\",\"chr2.bim\"),\n  famfiles = c(\"chr1.fam\",\"chr2.fam\")\n)\n\n## Optional grouping of markers used for multiple variance components\nfeatureSets &lt;- list(\n  set1 = 1:1000,\n  set2 = 1001:2000\n)\n\n## ------------------------------------------------------------------\n## Bayesian prior specification\n## ------------------------------------------------------------------\n## Priors replace variance components in Bayesian models.\n## Each prior corresponds to a named model component.\n\npriors &lt;- list(\n  dam = prior(\n    variable     = \"dam\",\n    traits       = c(\"BW\", \"Gl\"),\n    distribution = iw(df = 4, S = diag(1, 2)),\n    start        = diag(1, 2)\n  ),\n\n  animal = prior(\n    variable     = \"animal\",\n    traits       = c(\"BW\", \"Gl\"),\n    kernel       = PED,\n    distribution = iw(df = 4, S = diag(1, 2)),\n    start        = diag(1, 2)\n  ),\n\n  marker = prior(\n    variable     = \"animal\",\n    traits       = c(\"BW\", \"Gl\"),\n    featureMatrix     = featureMatrix,\n    featureSets  = featureSets,\n    distribution = bayesC(\n      pi     = beta(95, 5),\n      sigma2 = invchisq(df = 4, scale = 0.001),\n      start  = list(\n        set1 = diag(0.005, 2),\n        set2 = diag(0.001, 2)\n      )\n    )\n  ),\n\n  residual = prior(\n    variable     = \"residual\",\n    traits       = c(\"BW\", \"Gl\"),\n    distribution = iw(df = 4, S = diag(1, 2)),\n    start        = diag(1, 2)\n  )\n)\n\n## ------------------------------------------------------------------\n## Model fitting\n## ------------------------------------------------------------------\n## The estimation task determines how the model is fit,\n## without changing the model structure.\n\nfit_bayes &lt;- gfit(\n  formulas = formulas,\n  data     = data,\n  priors   = priors,\n  task     = \"bayes\"\n)\n\nThe same model specification can be estimated using a marker BLUP formulation by replacing prior() with vc() and setting task = \"solve\". The formulas, kernels, and feature matrices remain unchanged.\nAdditional worked examples for REML/solve and Bayesian mixed models (single- and multi-trait) are provided in the vignettes."
  },
  {
    "objectID": "index.html#classical-quantitative-genetics-case-studies-dmu-examples",
    "href": "index.html#classical-quantitative-genetics-case-studies-dmu-examples",
    "title": "qgtools",
    "section": "Classical quantitative genetics case studies (DMU examples)",
    "text": "Classical quantitative genetics case studies (DMU examples)\nqgtools is designed to express a wide range of classical quantitative genetic models while cleanly separating model structure from estimation strategy.\nTo demonstrate compatibility with established workflows, several standard examples from DMU are reproduced below using qgtools. In each case, the same model specification can be estimated using REML, solver-based BLUP, or Bayesian inference by changing only the estimation task.\n\nDMU-based examples\n\nGenotype × feeding system interaction\nMulti-trait model with unrelated sires and G×E expressed through cross-trait covariance.\nView example →\nDirect and maternal genetic effects in sheep growth\nMulti-trait pedigree model with direct genetic, maternal genetic, and environmental effects.\nView example →\nRandom regression model for growth hormone profiles\nLongitudinal random regression model with permanent environmental and additive genetic effects using Legendre polynomials.\nView example →\n\nThese examples illustrate how complex legacy DMU models translate directly into qgtools while benefiting from a clearer and more modular model specification."
  }
]